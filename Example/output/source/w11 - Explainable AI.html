<!DOCTYPE html>
<html>
  <head>
    <link rel="stylesheet" href="gothic.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Didact+Gothic&display=swap">

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="generator" content="pandoc">
    <meta name="description" content="">

    <title>w11 - Explainable AI</title>

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link href="https://maxcdn.bootstrapcdn.com/css/ie10-viewport-bug-workaround.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="https://mushiyo.github.io/pandoc-toc-sidebar/css/dashboard.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <style type="text/css">code{white-space: pre;}</style>
    <style type="text/css">.sidebar ul{padding-left: 10px;}</style>
    <link rel="stylesheet" href="gothic.css" />
  </head>

  <body>
    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container-fluid">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="../index.html">AI Ethics</a>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
            <li class="dropdown">
              <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Weeks 1-2 Background <span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="w1 - AI History.html">w1 - AI History</a></li>
                <li><a href="w2 - Intro of Ethics.html">w2 - Intro of Ethics</a></li>
               
              </ul>
            </li>

            <li class="dropdown">
              <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Weeks 3-5 Ethics Type <span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="w3 - Utilitarianism.html">w3 - Utilitarianism</a></li>
                <li><a href="w4 - Deontology.html">w4 - Deontology</a></li>
                <li><a href="w5 - Virtue ethic.html">w5 - Virtue ethic</a></li>
              </ul>
            </li>

            <li class="dropdown">
              <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Weeks 6-7 & 9 åˆ†ææ–¹å¼<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="w6 - Trust, justice, and accountability.html">w6 - Trust, justice, and accountability</a></li>
                <li><a href="w7 - Tranparency.html">w7 - Tranparency</a></li>
                <li><a href="w9 - Algorithmic Bias, Accessibility & Equity.html">w9 - Algorithmic Bias, Accessibility & Equity</a></li>
                
              </ul>
            </li>

            <li class="dropdown">
              <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Weeks 10-11 æ²»ç†<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="w10 - Data Governance.html">w10 - Data Governance</a></li>
                <li><a href="w11 - Explainable AI.html">w11 - Explainable AI</a></li>
              </ul>
            </li>        

            <li class="dropdown">
              <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Weeks 8 Guest<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="w8 - AI Ethic in Medicine.html">w8 - AI Ethic in Medicine</a></li>
              </ul>
          </ul>
        </div>
      </div>
    </nav>

    <div class="container-fluid">
      <div class="row">
        <div id="sidebar" class="col-sm-3 col-md-2 sidebar">
          <!--<ul class="nav nav-sidebar">
            <li class="active"><a href="#">Overview <span class="sr-only">(current)</span></a></li>
          </ul>-->
          <ul>
          <li><a href="#explainable-ai"
          id="toc-explainable-ai">Explainable AI</a>
          <ul>
          <li><a href="#why-ask-why" id="toc-why-ask-why">Why ask
          why?</a>
          <ul>
          <li><a href="#what-is-explainable-ai"
          id="toc-what-is-explainable-ai">What is Explainable
          AIï¼Ÿ</a></li>
          <li><a href="#who-care-xai" id="toc-who-care-xai">Who care
          XAI?</a></li>
          </ul></li>
          <li><a href="#the-challenges-of-xai"
          id="toc-the-challenges-of-xai">The challenges of XAI</a>
          <ul>
          <li><a href="#opacity-and-black-boxes"
          id="toc-opacity-and-black-boxes">Opacity and â€˜Black
          Boxes</a></li>
          <li><a href="#causality-å› æœå…³ç³»ç¼ºå¤±"
          id="toc-causality-å› æœå…³ç³»ç¼ºå¤±">Causality
          å› æœå…³ç³»ç¼ºå¤±</a></li>
          <li><a href="#the-human-problem"
          id="toc-the-human-problem">The Human Problem</a></li>
          </ul></li>
          <li><a href="#properties-of-xai-approaches"
          id="toc-properties-of-xai-approaches">Properties of XAI
          approaches</a>
          <ul>
          <li><a href="#local-vs-global-explanation"
          id="toc-local-vs-global-explanation">Local vs Global
          Explanation</a></li>
          <li><a
          href="#interpretability-vs-post-hoc-explanationå¯è§£é‡Šæ€§-vs-åéªŒè§£é‡Š"
          id="toc-interpretability-vs-post-hoc-explanationå¯è§£é‡Šæ€§-vs-åéªŒè§£é‡Š">Interpretability
          vs Post-hoc Explanationï¼ˆå¯è§£é‡Šæ€§ vs åéªŒè§£é‡Šï¼‰</a></li>
          <li><a href="#example-decision-tree-vs-neural-network"
          id="toc-example-decision-tree-vs-neural-network">Example:
          Decision Tree vs Neural Network</a></li>
          <li><a href="#model-agnostic-vs-model-specific"
          id="toc-model-agnostic-vs-model-specific">Model-Agnostic vs
          Model-Specific</a></li>
          </ul></li>
          <li><a href="#explainable-ai-methods"
          id="toc-explainable-ai-methods">Explainable AI Methods</a>
          <ul>
          <li><a href="#rule-based-explanation"
          id="toc-rule-based-explanation">1. Rule-based Explanation</a>
          <ul>
          <li><a href="#limitations"
          id="toc-limitations">Limitations</a></li>
          </ul></li>
          <li><a href="#attribution-based-explanations"
          id="toc-attribution-based-explanations">2. Attribution-based
          Explanations</a>
          <ul>
          <li><a href="#limitations-1"
          id="toc-limitations-1">Limitations</a></li>
          </ul></li>
          <li><a href="#example-based-explanations"
          id="toc-example-based-explanations">3. Example-based
          Explanations</a>
          <ul>
          <li><a href="#method-1prototypes-and-criticisms"
          id="toc-method-1prototypes-and-criticisms">Method
          1:<strong>Prototypes and Criticisms</strong></a></li>
          <li><a href="#method-2-counterfactual-explanations"
          id="toc-method-2-counterfactual-explanations">Method 2:
          <strong>Counterfactual Explanations</strong></a></li>
          <li><a href="#limitations-2"
          id="toc-limitations-2">Limitations</a></li>
          <li><a href="#method-3-contrastive-explanations"
          id="toc-method-3-contrastive-explanations">Method 3:
          <strong>Contrastive Explanations</strong></a></li>
          </ul></li>
          </ul></li>
          <li><a href="#ethical-philosophical-considerations"
          id="toc-ethical-philosophical-considerations">Ethical &amp;
          Philosophical Considerations</a>
          <ul>
          <li><a href="#principles-for-ai-in-society"
          id="toc-principles-for-ai-in-society">Principles for AI in
          Society</a></li>
          </ul></li>
          <li><a href="#mind-map" id="toc-mind-map">Mind Map</a></li>
          </ul></li>
          </ul>
        </div>
        <div class="col-sm-9 col-sm-offset-3 col-md-10 col-md-offset-2 main">
        
<h1 id="explainable-ai">Explainable AI</h1>
<h2 id="why-ask-why">Why ask why?</h2>
<p>ä½ æ˜¯ä¸€åæˆç»©ä¼˜å¼‚çš„æ¯•ä¸šç”Ÿï¼Œç”³è¯·äº†ä¸€ä¸ªç†æƒ³å·¥ä½œå²—ä½ï¼Œ30
ç§’åå°±æ”¶åˆ°äº†æ‹’ç»é‚®ä»¶â€”â€”ç†ç”±å®Œå…¨ä¸æ¸…æ¥šã€‚ä½ æƒ³çŸ¥é“ä¸ºä»€ä¹ˆï¼Œä½†å…¬å¸å‘Šè¯‰ä½ ï¼šâ€œæˆ‘ä»¬ä½¿ç”¨é«˜çº§æœºå™¨å­¦ä¹ ç®—æ³•åšå†³å®šï¼Œæ— æ³•æä¾›è§£é‡Šã€‚-&gt;
we need explain!</p>
<h3 id="what-is-explainable-ai">What is Explainable AIï¼Ÿ</h3>
<p>Explainable AI æ˜¯ä¸€ç±» AI
æŠ€æœ¯å’Œæ–¹æ³•ï¼Œå®ƒä»¬å¯ä»¥è§£é‡Šæœºå™¨å­¦ä¹ ç³»ç»Ÿæ˜¯å¦‚ä½•å¾—å‡ºå†³ç­–çš„ã€‚</p>
<blockquote>
<p>Explainable Artificial Intelligence (XAI) refers to methods and
techniques in the field of AI that provide more understanding of AI
(machine learning) systems and how they reach their decisions.</p>
</blockquote>
<ol type="1">
<li><p><strong>Transparencyï¼ˆé€æ˜æ€§ï¼‰</strong>ï¼š</p>
<blockquote>
<p>â€œXAI helps in making the decision-making processes of AI systems
transparent.â€ å®ƒä½¿å¾—æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹å¯¹ç”¨æˆ·å’Œå¼€å‘è€…å¯è§ã€‚</p>
</blockquote></li>
<li><p><strong>Trust &amp; Confidenceï¼ˆå»ºç«‹ä¿¡ä»»ï¼‰</strong>ï¼š</p>
<blockquote>
<p>â€œCan increase user trust and confidence in AI applications,
especially in critical areas.â€
åœ¨åŒ»ç–—ã€é‡‘èã€å¸æ³•ç­‰é«˜é£é™©é¢†åŸŸå°¤å…¶é‡è¦ã€‚</p>
</blockquote></li>
<li><p><strong>Regulatory Complianceï¼ˆæ³•å¾‹åˆè§„ï¼‰</strong>ï¼š</p>
<blockquote>
<p>â€œHelp ensure compliance withâ€¦ such as GDPRâ€™s right to explanation.â€
æ¯”å¦‚ GDPRï¼ˆé€šç”¨æ•°æ®ä¿æŠ¤æ¡ä¾‹ï¼‰è§„å®šç”¨æˆ·æœ‰â€œè§£é‡Šæƒâ€ã€‚</p>
</blockquote></li>
</ol>
<h3 id="who-care-xai">Who care XAI?</h3>
<table>
<colgroup>
<col style="width: 14%" />
<col style="width: 48%" />
<col style="width: 37%" />
</colgroup>
<thead>
<tr>
<th>Stakeholder</th>
<th>åŸæ–‡ä¸¾ä¾‹ä¸è¯´æ˜</th>
<th>ä¸­æ–‡è¯´æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td>Data Scientists</td>
<td>â€œUnderstand, debug, improve model performance.â€</td>
<td>æƒ³äº†è§£å’Œæ”¹è¿›æ¨¡å‹æ€§èƒ½çš„<strong>æŠ€æœ¯ä¸“å®¶</strong></td>
</tr>
<tr>
<td>Business Owners</td>
<td>â€œEvaluate suitability, accept use.â€</td>
<td>å…³å¿ƒ<strong>å•†ä¸š</strong>å¯è¡Œæ€§ä¸<strong>å…¬å¸</strong>è´£ä»»çš„å†³ç­–è€…</td>
</tr>
<tr>
<td>Risk Modellers</td>
<td>â€œChallenge model, ensure robustness.â€</td>
<td>åšæ¨¡å‹<strong>å®¡æ ¸</strong>ä¸éªŒè¯çš„é£é™©åˆ†æäººå‘˜</td>
</tr>
<tr>
<td>Regulators</td>
<td>â€œCheck impact, verify reliability.â€</td>
<td><strong>ç›‘ç®¡</strong>äººå‘˜ï¼Œç¡®ä¿åˆæ³•æ€§ä¸å…¬å¹³æ€§</td>
</tr>
<tr>
<td>Consumers</td>
<td>â€œWhatâ€™s the impact on me? What actions can I take?â€</td>
<td><strong>æœ€ç»ˆç”¨æˆ·</strong>ï¼Œæƒ³çŸ¥é“å½±å“ä¸åº”å¯¹æ–¹æ³•</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="the-challenges-of-xai">The challenges of XAI</h2>
<h3 id="opacity-and-black-boxes">Opacity and â€˜Black Boxes</h3>
<p>â€œOpacityâ€
æŒ‡ç³»ç»Ÿä¸é€æ˜ã€ä¸å¯çœ‹ç©¿ï¼Œæ­£å¥½ä¸â€œtransparencyï¼ˆé€æ˜æ€§ï¼‰â€ç›¸åã€‚é»‘ç®±æ¨¡å‹å°±æ˜¯å…¸å‹çš„
opaque systemã€‚</p>
<p>Black box çš„é—®é¢˜åœ¨äºï¼ŒWhile it works, it doesnâ€™t explain why it
works, which is unacceptable in high-risk scenarios (e.g., medical,
judicial).</p>
<h3 id="causality-å› æœå…³ç³»ç¼ºå¤±">Causality å› æœå…³ç³»ç¼ºå¤±</h3>
<blockquote>
<p>â€œMachine learning excels at <mark>finding correlations</mark>â€¦ but
not grounded in <mark>causal reasoning</mark>.â€ â†’
æœºå™¨å­¦ä¹ å–„äºæ‰¾åˆ°ç›¸å…³æ€§ï¼Œä½†é€šå¸¸æ— æ³•æ¨æ–­å› æœå…³ç³»ã€‚</p>
</blockquote>
<ul>
<li><p>Lifestyle â†’ Smoking &amp; Alcohol</p>
<p>Smoking â†’ Lung Cancer</p>
<p>Alcohol ä¸ Lung Cancer
çš„å…³ç³»åªæ˜¯ç›¸å…³ï¼ˆcorrelationï¼‰ï¼Œä¸æ˜¯å› æœï¼ˆcausationï¼‰</p></li>
</ul>
<h3 id="the-human-problem">The Human Problem</h3>
<blockquote>
<p>â€œMuch if not most of XAI is driven by the desire of AI experts to
better understand their modelsâ€¦â€ <mark>But we also need explanations for
non-experts.</mark> XAI
çš„ç ”ç©¶å¾€å¾€<strong>ä»¥æŠ€æœ¯äººå‘˜ä¸ºä¸­å¿ƒ</strong>ï¼Œå…³æ³¨è°ƒè¯•ã€ä¼˜åŒ–æ¨¡å‹ï¼Œä½†å¿½ç•¥äº†éæŠ€æœ¯ç”¨æˆ·çš„ç†è§£éœ€æ±‚ã€‚</p>
</blockquote>
<hr />
<h2 id="properties-of-xai-approaches">Properties of XAI approaches</h2>
<h3 id="local-vs-global-explanation">Local vs Global Explanation</h3>
<p>Local is å¯¹<strong>æŸä¸€ä¸ªè¾“å…¥å®ä¾‹</strong>çš„è§£é‡Š, Global is
å¯¹<strong>æ•´ä¸ªæ¨¡å‹è¡Œä¸º</strong>çš„è§£é‡Š</p>
<ul>
<li><p><strong>Local explanation</strong>: refers to insights that
explain the <strong>decision-making process</strong> of an AI</p>
<p>model <strong>for a specific instance or input</strong> (e.g.Â why did
<em>my</em> application get rejected?)</p></li>
<li><p><strong>Global explanation</strong>: refers to insights that
explain the <strong>overall behaviour and decision- making
process</strong> of an AI model <strong>across all possible inputs and
scenarios</strong> (e.g.Â how does this model make decisions across some
consumer population?)</p></li>
</ul>
<h3
id="interpretability-vs-post-hoc-explanationå¯è§£é‡Šæ€§-vs-åéªŒè§£é‡Š">Interpretability
vs Post-hoc Explanationï¼ˆå¯è§£é‡Šæ€§ vs åéªŒè§£é‡Šï¼‰</h3>
<p>Interpretability: æ¨¡å‹<strong>æœ¬èº«</strong>æ˜“äºç†è§£ inherently
understandable.</p>
<p>Explanation: explanation of <mark>output</mark> and decision making
<mark>ï¼ˆBlack Boxï¼‰</mark></p>
<p>Post-hoc:
æ¨¡å‹å·²ç»<strong>è®­ç»ƒå¥½å¹¶ç»™å‡ºé¢„æµ‹ç»“æœä¹‹å</strong>ï¼Œæˆ‘ä»¬å†è¯•å›¾è§£é‡Šè¿™ä¸ªç»“æœæ˜¯å¦‚ä½•äº§ç”Ÿçš„ã€‚</p>
<p>ä»æŸç§æ„ä¹‰ä¸Šè¯´ï¼ŒInterpretabilityæ„å‘³ç€Explanationï¼Œä½†Explanationå¹¶ä¸ä¸€å®šæ„å‘³ç€Interpretability</p>
<ul>
<li>ä¸€ä¸ªé»‘ç®±æ¨¡å‹å¯ä»¥ç”¨ post-hoc
æ–¹æ³•è§£é‡Šè¾“å‡ºï¼Œä½†è¿™å¹¶ä¸æ„å‘³ç€ä½ çœŸçš„ç†è§£äº†æ¨¡å‹æœ¬èº«ã€‚</li>
</ul>
<h3 id="example-decision-tree-vs-neural-network">Example: Decision Tree
vs Neural Network</h3>
<p><strong>Interpretableï¼šDecision Tree</strong></p>
<ul>
<li>è¾“å…¥ä¸€äº›ç‰¹å¾ï¼Œå¦‚â€œæ˜¯å¦æœ‰åˆºâ€ã€â€œç¿…è†€æ•°é‡â€ã€â€œçœ¼ç›æ•°â€</li>
<li>æ¨¡å‹è·¯å¾„æ¸…æ™° â†’ è¾“å‡ºç»“æœä¸ºâ€œBeeâ€æˆ–â€œFlyâ€ç­‰</li>
</ul>
<p><strong>Post-hoc ç¤ºä¾‹ï¼šç¥ç»ç½‘ç»œè¯†åˆ«ç‹¼å’Œå“ˆå£«å¥‡</strong></p>
<ul>
<li>æ¨¡å‹è®­ç»ƒæ—¶æ„å¤–å­¦ä¼šäº†â€œèƒŒæ™¯é›ªåœ° = ç‹¼â€</li>
<li>ä¸€å¼ å“ˆå£«å¥‡ç…§ç‰‡å› èƒŒæ™¯æœ‰é›ªè¢«é”™åˆ¤ä¸ºç‹¼</li>
</ul>
<h3 id="model-agnostic-vs-model-specific">Model-Agnostic vs
Model-Specific</h3>
<ul>
<li><p><strong>Model-specific</strong>: refers to methods that are
designed to provide insights or explanations</p>
<p>tailored to the internal mechanisms and architecture of a specific
type of AI model.</p>
<ul>
<li>inner workings of model used for explanation</li>
<li>ä¾èµ–äºå…·ä½“æ¨¡å‹ç»“æ„ï¼ˆå¦‚ç¥ç»ç½‘ç»œã€å†³ç­–æ ‘ï¼‰</li>
</ul></li>
<li><p><strong>Model-agnostic</strong>: refers to methods that can
provide insights or explanations for any AI modelâ€™s decisions,
regardless of the modelâ€™s internal architecture or workings.</p>
<ul>
<li>ä¸ä¾èµ–æ¨¡å‹å†…éƒ¨ç»“æ„ï¼Œåªç”¨è¾“å…¥å’Œè¾“å‡º</li>
</ul></li>
</ul>
<p>â€’ uses only inputs and outputs for explanation â€’ applicable to any
model with that interface</p>
<hr />
<h2 id="explainable-ai-methods">Explainable AI Methods</h2>
<h3 id="rule-based-explanation">1. Rule-based Explanation</h3>
<p>ä½¿ç”¨æ˜ç¡®çš„ <mark style="background-color: #90ee90;"> if-then </mark>
è§„åˆ™ æ¥è§£é‡Šæ¨¡å‹æ˜¯å¦‚ä½•ä»è¾“å…¥æ¨ç†å‡ºè¾“å‡ºçš„ã€‚</p>
<blockquote>
<p>â€œUse of explicit rules to describe how a model makes decisions.â€</p>
</blockquote>
<h4 id="limitations">Limitations</h4>
<p>ä¸é€‚ç”¨äºå¤æ‚ä»»åŠ¡</p>
<h3 id="attribution-based-explanations">2. Attribution-based
Explanations</h3>
<blockquote>
<p>â€œDetermining the contribution of individual input features to the
output.â€
è¡¡é‡è¾“å…¥ä¸­<strong>å“ªäº›éƒ¨åˆ†</strong>æœ€é‡è¦ï¼Œæœ€è´Ÿè´£æ¨¡å‹çš„é¢„æµ‹ç»“æœã€‚</p>
</blockquote>
<blockquote>
<p>[!TIP]</p>
<p>æˆ‘ä»¬è®­ç»ƒäº†ä¸€ä¸ª
<strong>å›¾åƒåˆ†ç±»æ¨¡å‹</strong>ï¼Œç”¨æ¥è¯†åˆ«å›¾åƒä¸­æ˜¯ä»€ä¹ˆåŠ¨ç‰©ï¼Œæ¯”å¦‚ç‹—ã€çŒ«ã€é©¬ã€‚</p>
<p>ä½ è¾“å…¥äº†ä¸€å¼ ç‹—çš„ç…§ç‰‡ï¼Œæ¨¡å‹è¾“å‡ºï¼šâ€œç‹— ğŸ¶â€ã€‚</p>
<p>ä½ æƒ³çŸ¥é“ï¼šâ€œå®ƒä¸ºä»€ä¹ˆè®¤ä¸ºè¿™æ˜¯ä¸€åªç‹—ï¼Ÿâ€</p>
<p>Saliency map æŠŠæ¨¡å‹æœ€å…³æ³¨çš„åŒºåŸŸç”¨çº¢è‰²/é«˜äº®æ ‡å‡ºæ¥ã€‚</p>
</blockquote>
<blockquote>
<p>[!TIP]</p>
<blockquote>
<p>â€œThe food was absolutely terrible and the waiter was rude.â€</p>
</blockquote>
<p>ä½ ç”¨ä¸€ä¸ªæƒ…æ„Ÿåˆ†ææ¨¡å‹ï¼Œå®ƒè¾“å‡ºï¼š<strong>Negative</strong>ï¼ˆè´Ÿé¢æƒ…ç»ªï¼‰</p>
<p>Attribution æ–¹æ³•ï¼ˆå¦‚ SHAPï¼‰ä¼šå‘Šè¯‰ä½ ï¼š</p>
<ul>
<li>â€œterribleâ€ è´¡çŒ®äº† 70% çš„è´Ÿé¢</li>
<li>â€œrudeâ€ è´¡çŒ®äº† 20%</li>
<li>â€œabsolutelyâ€ è´¡çŒ®äº† 10% â†’ æ‰€ä»¥ä½ å¯ä»¥çŸ¥é“
<strong>å“ªä¸ªè¯å¯¹æƒ…ç»ªåˆ¤æ–­æœ€é‡è¦</strong>ã€‚</li>
</ul>
</blockquote>
<h4 id="limitations-1">Limitations</h4>
<p>While helpful, these methods can sometimes be <mark>computationally
expensive</mark> or provide explanations that are <mark>not
intuitive</mark> for end-users, depending on the complexity of the model
and the data involved.</p>
<h3 id="example-based-explanations">3. Example-based Explanations</h3>
<blockquote>
<p>Example-based explanations in XAI provide insights into model
behaviour by <mark>highlighting specific instances from the data
set</mark>.
å±•ç¤ºæ¨¡å‹çš„â€œåŸå‹æ ·æœ¬â€ã€â€œè¾¹ç•Œå¼‚å¸¸æ ·æœ¬â€æˆ–â€œåäº‹å®æ ·æœ¬â€æ¥è§£é‡Šè¡Œä¸º</p>
</blockquote>
<h4 id="method-1prototypes-and-criticisms">Method 1:<strong>Prototypes
and Criticisms</strong></h4>
<p>åŸå‹ï¼ˆPrototypeï¼‰ï¼šæœ€èƒ½ä»£è¡¨æŸç±»åˆ«çš„å…¸å‹æ ·æœ¬</p>
<p><img src="./f8kj36.png"
alt="image-20250620090602037" />æ‰¹è¯„æ ·æœ¬ï¼ˆCriticism)ï¼šå±äºè¯¥ç±»ä½†æœ‰äº›å¼‚å¸¸çš„â€œè¾¹ç•Œâ€æ ·æœ¬.</p>
<h4 id="method-2-counterfactual-explanations">Method 2:
<strong>Counterfactual Explanations</strong></h4>
<p>åäº‹å®ï¼š<mark style="background-color: #90ee90;"> what if</mark> I
didâ€¦, can I get diff outcome?</p>
<p>-&gt; å¦‚æœæˆ‘æœ‰100kï¼Œæˆ‘ä¼šå¹²å˜›å¹²å˜›å—ï¼Ÿ</p>
<h4 id="limitations-2">Limitations</h4>
<p>éœ€ç²¾å¿ƒè®¾è®¡ what-ifé—®é¢˜</p>
<h4 id="method-3-contrastive-explanations">Method 3: <strong>Contrastive
Explanations</strong></h4>
<p>å¼ºè°ƒæ¨¡å‹ä¸ºä»€ä¹ˆé€‰æ‹©äº†ç»“æœ Aï¼Œè€Œä¸æ˜¯ B</p>
<p><mark style="background-color: #90ee90;"> Why a, not b?</mark></p>
<h2 id="ethical-philosophical-considerations">Ethical &amp;
Philosophical Considerations</h2>
<h3 id="principles-for-ai-in-society">Principles for AI in Society</h3>
<table>
<colgroup>
<col style="width: 18%" />
<col style="width: 40%" />
<col style="width: 40%" />
</colgroup>
<thead>
<tr>
<th>åŸåˆ™å</th>
<th>è®²ä¹‰å†…å®¹ç®€è¿°ï¼ˆslidesï¼‰</th>
<th>è®²è€…è§£é‡Šä¸æ‰©å±•ï¼ˆtranscriptï¼‰</th>
</tr>
</thead>
<tbody>
<tr>
<td>Beneficence</td>
<td>Promote well-being, dignity, sustainability</td>
<td>&gt; â€œAI should promote well-being, preserve dignity and sustain the
planet.â€â†’ AI åº”è¯¥è¢«ç”¨æ¥åšå–„äº‹ã€ä¿ƒè¿›äººç±»ç¦ç¥‰</td>
</tr>
<tr>
<td>Non-maleficenceï¼ˆno harmï¼‰</td>
<td>Privacy, Security, Capability Caution</td>
<td>&gt; â€œDonâ€™t do badâ€¦ avoid harm such as violating privacy.â€â†’
åŒ…æ‹¬å°Šé‡éšç§ã€å®‰å…¨ã€è°¨æ…å‘å±•å¼º AI</td>
</tr>
<tr>
<td>Autonomy</td>
<td>The power to decide, informed consent</td>
<td>&gt; â€œLike informed consent in medicineâ€¦ users should consent to how
AI is used for them.â€</td>
</tr>
<tr>
<td>Justice</td>
<td>Prosperity, solidarity, fairness</td>
<td>&gt; â€œPromoting prosperity, avoiding unfairnessâ€¦ like algorithmic
biasâ€â†’ æˆ‘ä»¬åœ¨â€œBiasâ€é‚£ä¸€è®²é‡ç‚¹è®¨è®ºè¿‡</td>
</tr>
<tr>
<td>Explicability</td>
<td>Enabling the other principles through:</td>
<td></td>
</tr>
<tr>
<td>Intelligibilit<br />å¯ç†è§£æ€§</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Accountability</td>
<td>â€œExplicability is foundational. It underpins all the other
principles.â€</td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="mind-map">Mind Map</h2>
<ul>
<li><p>Different stakeholders with different explainability
requirements</p></li>
<li><p>Goals:</p>
<p>â€’ improvedecision-making</p>
<p>â€’ ethics and accountability</p></li>
<li><p>Human and technical challenges:</p></li>
<li><p>opacity</p></li>
<li><p>causality</p></li>
<li><p>human interpretation, non-expert end users</p></li>
<li><p>Properties:</p></li>
<li><p>local versus global</p></li>
<li><p>interpretable versus post-hoc</p></li>
<li><p>model-agnostic versus model-specific</p></li>
<li><p>Methods:</p>
<ul>
<li><p>rule-based</p></li>
<li><p>attribution-based</p></li>
<li><p>example-based</p></li>
</ul></li>
</ul>
        </div>
      </div>
    </div>
    
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="https://maxcdn.bootstrapcdn.com/js/ie10-viewport-bug-workaround.js"></script>
    <script>
        //document.getElementById('sidebar').getElementsByTagName('ul')[0].className += "nav nav-sidebar";
        
        /* ajust the height when click the toc
           the code is from https://github.com/twbs/bootstrap/issues/1768
        */
        var shiftWindow = function() { scrollBy(0, -50) };
        window.addEventListener("hashchange", shiftWindow);
        function load() { if (window.location.hash) shiftWindow(); }
        
        /*add Bootstrap styles to tables*/
        var tables = document.getElementsByTagName("table");
        for(var i = 0; i < tables.length; ++i){
            tables[i].className += "table table-bordered table-hover";
        }

        /* Add quote styles */
  
        document.addEventListener("DOMContentLoaded", function () {
          document.querySelectorAll("blockquote").forEach(function (block) {
            const first = block.querySelector("p");
            if (!first) return;
            const text = first.textContent.trim();

            if (text.startsWith("[!NOTE]")) {
              block.classList.add("note");
              first.innerHTML = "<strong>NOTE</strong>" + first.innerHTML.replace("[!NOTE]", "");
            } else if (text.startsWith("[!TIP]")) {
              block.classList.add("tip");
              first.innerHTML = "<strong>TIP</strong>" + first.innerHTML.replace("[!TIP]", "");
            } else if (text.startsWith("[!WARNING]")) {
              block.classList.add("warning");
              first.innerHTML = "<strong>WARNING</strong>" + first.innerHTML.replace("[!WARNING]", "");
            }
          });
        });

        document.addEventListener('DOMContentLoaded', function () {
          var links = document.querySelectorAll('a[href]');
          for (var i = 0; i < links.length; i++) {
            var href = links[i].getAttribute('href');
            if (!href) continue;

            if (href.indexOf('.md#') !== -1) {
              var parts = href.split('.md#');
              var newHref = parts[0] + '.html#' + parts[1];
              links[i].setAttribute('href', newHref);
            } else if (href.length > 3 && href.slice(-3) === '.md') {
              var newHref = href.slice(0, -3) + '.html';
              links[i].setAttribute('href', newHref);
            }
          }
        });




    </script>
  </body>
</html>
